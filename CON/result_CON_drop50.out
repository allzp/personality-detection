SLURM_JOBID=193909
SLURM_JOB_NODELIST=hbcomp-012
SLURM_NNODES=1
SLURMTMPDIR=
working directory=/hb/home/yweng5/personality-detection-master_git
/hb/software/apps/python/gnu-3.6.2/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
/hb/software/apps/python/gnu-3.6.2/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
WARNING:tensorflow:From personality_CON.py:185: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /hb/software/apps/python/gnu-3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /hb/software/apps/python/gnu-3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
2018-06-10 14:43:16.842432: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/hb/home/yweng5
/hb/home/yweng5/glove.6B.300d.txt
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Embedding_1 (Embedding)      (None, 129, 149, 300)     7638300   
_________________________________________________________________
Dropout_in (Dropout)         (None, 129, 149, 300)     0         
_________________________________________________________________
LSTM_1 (TimeDistributed)     (None, 129, 300)          721200    
_________________________________________________________________
Dropout_LSTM1 (Dropout)      (None, 129, 300)          0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 300)               0         
=================================================================
Total params: 8,359,500
Trainable params: 8,359,500
Non-trainable params: 0
_________________________________________________________________
None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 84)                0         
=================================================================
Total params: 0
Trainable params: 0
Non-trainable params: 0
_________________________________________________________________
None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Merge (Merge)                (None, 384)               0         
_________________________________________________________________
hidden_layer (Dense)         (None, 16)                6160      
_________________________________________________________________
Dense_out (Dense)            (None, 1)                 17        
=================================================================
Total params: 8,365,677
Trainable params: 8,365,677
Non-trainable params: 0
_________________________________________________________________
None
Train on 1726 samples, validate on 741 samples
Epoch 1/50

 200/1726 [==>...........................] - ETA: 5:25 - loss: 0.7082 - acc: 0.4650
 400/1726 [=====>........................] - ETA: 4:41 - loss: 0.7020 - acc: 0.4875
 600/1726 [=========>....................] - ETA: 3:57 - loss: 0.6954 - acc: 0.5067
 800/1726 [============>.................] - ETA: 3:15 - loss: 0.6954 - acc: 0.5125
1000/1726 [================>.............] - ETA: 2:33 - loss: 0.6937 - acc: 0.5190
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6929 - acc: 0.5225
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6927 - acc: 0.5250
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6926 - acc: 0.5225 
1726/1726 [==============================] - 416s 241ms/step - loss: 0.6933 - acc: 0.5191 - val_loss: 0.7046 - val_acc: 0.4831
Epoch 2/50

 200/1726 [==>...........................] - ETA: 5:20 - loss: 0.6905 - acc: 0.5000
 400/1726 [=====>........................] - ETA: 4:38 - loss: 0.6878 - acc: 0.5125
 600/1726 [=========>....................] - ETA: 3:56 - loss: 0.6844 - acc: 0.5250
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6839 - acc: 0.5387
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6852 - acc: 0.5400
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6857 - acc: 0.5425
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6857 - acc: 0.5464
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6845 - acc: 0.5506 
1726/1726 [==============================] - 414s 240ms/step - loss: 0.6843 - acc: 0.5521 - val_loss: 0.6996 - val_acc: 0.4791
Epoch 3/50

 200/1726 [==>...........................] - ETA: 5:20 - loss: 0.6805 - acc: 0.5350
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6758 - acc: 0.5600
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6766 - acc: 0.5667
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6757 - acc: 0.5700
1000/1726 [================>.............] - ETA: 2:32 - loss: 0.6746 - acc: 0.5660
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6746 - acc: 0.5725
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6763 - acc: 0.5657
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6790 - acc: 0.5537 
1726/1726 [==============================] - 415s 241ms/step - loss: 0.6784 - acc: 0.5597 - val_loss: 0.6977 - val_acc: 0.4804
Epoch 4/50

 200/1726 [==>...........................] - ETA: 5:19 - loss: 0.6815 - acc: 0.5550
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6825 - acc: 0.5500
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6818 - acc: 0.5400
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6793 - acc: 0.5550
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6760 - acc: 0.5640
1200/1726 [===================>..........] - ETA: 1:49 - loss: 0.6730 - acc: 0.5700
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6727 - acc: 0.5736
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6739 - acc: 0.5713 
1726/1726 [==============================] - 415s 240ms/step - loss: 0.6727 - acc: 0.5771 - val_loss: 0.6958 - val_acc: 0.4939
Epoch 5/50

 200/1726 [==>...........................] - ETA: 5:20 - loss: 0.6612 - acc: 0.5600
 400/1726 [=====>........................] - ETA: 4:38 - loss: 0.6641 - acc: 0.5800
 600/1726 [=========>....................] - ETA: 3:56 - loss: 0.6743 - acc: 0.5483
 800/1726 [============>.................] - ETA: 3:14 - loss: 0.6754 - acc: 0.5475
1000/1726 [================>.............] - ETA: 2:32 - loss: 0.6754 - acc: 0.5500
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6720 - acc: 0.5583
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6708 - acc: 0.5643
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6707 - acc: 0.5669 
1726/1726 [==============================] - 415s 240ms/step - loss: 0.6711 - acc: 0.5678 - val_loss: 0.6951 - val_acc: 0.4993
Epoch 6/50

 200/1726 [==>...........................] - ETA: 5:20 - loss: 0.6606 - acc: 0.5800
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6603 - acc: 0.5975
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6630 - acc: 0.5983
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6656 - acc: 0.5888
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6663 - acc: 0.5930
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6664 - acc: 0.5950
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6695 - acc: 0.5921
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6687 - acc: 0.5931 
1726/1726 [==============================] - 415s 241ms/step - loss: 0.6683 - acc: 0.5939 - val_loss: 0.6941 - val_acc: 0.4980
Epoch 7/50

 200/1726 [==>...........................] - ETA: 5:20 - loss: 0.6657 - acc: 0.5900
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6710 - acc: 0.5875
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6713 - acc: 0.5883
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6683 - acc: 0.5887
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6656 - acc: 0.5990
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6639 - acc: 0.6008
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6657 - acc: 0.5950
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6660 - acc: 0.5937 
1726/1726 [==============================] - 415s 241ms/step - loss: 0.6658 - acc: 0.5927 - val_loss: 0.6930 - val_acc: 0.4939
Epoch 8/50

 200/1726 [==>...........................] - ETA: 5:21 - loss: 0.6576 - acc: 0.6000
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6573 - acc: 0.5875
 600/1726 [=========>....................] - ETA: 3:56 - loss: 0.6638 - acc: 0.5700
 800/1726 [============>.................] - ETA: 3:14 - loss: 0.6591 - acc: 0.5888
1000/1726 [================>.............] - ETA: 2:32 - loss: 0.6598 - acc: 0.5930
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6598 - acc: 0.5967
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6616 - acc: 0.5957
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6636 - acc: 0.5931 
1726/1726 [==============================] - 416s 241ms/step - loss: 0.6640 - acc: 0.5921 - val_loss: 0.6930 - val_acc: 0.4899
Epoch 9/50

 200/1726 [==>...........................] - ETA: 5:19 - loss: 0.6750 - acc: 0.5550
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6549 - acc: 0.6050
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6626 - acc: 0.5950
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6688 - acc: 0.5850
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6677 - acc: 0.5930
1200/1726 [===================>..........] - ETA: 1:49 - loss: 0.6650 - acc: 0.5925
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6636 - acc: 0.5943
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6631 - acc: 0.5962 
1726/1726 [==============================] - 414s 240ms/step - loss: 0.6624 - acc: 0.5979 - val_loss: 0.6920 - val_acc: 0.4966
Epoch 10/50

 200/1726 [==>...........................] - ETA: 5:18 - loss: 0.6543 - acc: 0.5900
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6616 - acc: 0.5875
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6521 - acc: 0.6050
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6567 - acc: 0.6037
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6562 - acc: 0.6100
1200/1726 [===================>..........] - ETA: 1:49 - loss: 0.6571 - acc: 0.6092
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6580 - acc: 0.6079
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6605 - acc: 0.6025 
1726/1726 [==============================] - 415s 240ms/step - loss: 0.6615 - acc: 0.6002 - val_loss: 0.6918 - val_acc: 0.5101
Epoch 11/50

 200/1726 [==>...........................] - ETA: 5:19 - loss: 0.6364 - acc: 0.6100
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6434 - acc: 0.6275
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6512 - acc: 0.6050
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6599 - acc: 0.5950
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6601 - acc: 0.5990
1200/1726 [===================>..........] - ETA: 1:49 - loss: 0.6596 - acc: 0.6033
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6603 - acc: 0.5950
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6601 - acc: 0.5994 
1726/1726 [==============================] - 414s 240ms/step - loss: 0.6598 - acc: 0.5991 - val_loss: 0.6931 - val_acc: 0.5034
Epoch 12/50

 200/1726 [==>...........................] - ETA: 5:19 - loss: 0.6409 - acc: 0.6200
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6505 - acc: 0.6000
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6498 - acc: 0.6067
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6540 - acc: 0.5938
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6586 - acc: 0.5820
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6572 - acc: 0.5958
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6577 - acc: 0.5993
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6577 - acc: 0.6019 
1726/1726 [==============================] - 414s 240ms/step - loss: 0.6596 - acc: 0.5973 - val_loss: 0.6927 - val_acc: 0.5155
personality_CON.py:283: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.
  merged = Merge([modelleft,modelright], mode='concat',name='Merge')
