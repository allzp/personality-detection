SLURM_JOBID=193887
SLURM_JOB_NODELIST=hbcomp-018
SLURM_NNODES=1
SLURMTMPDIR=
working directory=/hb/home/yweng5/personality-detection-master_git
/hb/software/apps/python/gnu-3.6.2/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
/hb/software/apps/python/gnu-3.6.2/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
WARNING:tensorflow:From personality_NEU.py:185: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /hb/software/apps/python/gnu-3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /hb/software/apps/python/gnu-3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
2018-06-10 12:24:24.881895: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/hb/home/yweng5
/hb/home/yweng5/glove.6B.300d.txt
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Embedding_1 (Embedding)      (None, 129, 149, 300)     7638300   
_________________________________________________________________
Dropout_in (Dropout)         (None, 129, 149, 300)     0         
_________________________________________________________________
LSTM_1 (TimeDistributed)     (None, 129, 300)          721200    
_________________________________________________________________
Dropout_LSTM1 (Dropout)      (None, 129, 300)          0         
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 300)               0         
=================================================================
Total params: 8,359,500
Trainable params: 8,359,500
Non-trainable params: 0
_________________________________________________________________
None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 84)                0         
=================================================================
Total params: 0
Trainable params: 0
Non-trainable params: 0
_________________________________________________________________
None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Merge (Merge)                (None, 384)               0         
_________________________________________________________________
hidden_layer (Dense)         (None, 16)                6160      
_________________________________________________________________
Dense_out (Dense)            (None, 1)                 17        
=================================================================
Total params: 8,365,677
Trainable params: 8,365,677
Non-trainable params: 0
_________________________________________________________________
None
Train on 1726 samples, validate on 741 samples
Epoch 1/50

 200/1726 [==>...........................] - ETA: 5:28 - loss: 0.6922 - acc: 0.5450
 400/1726 [=====>........................] - ETA: 4:41 - loss: 0.6990 - acc: 0.5100
 600/1726 [=========>....................] - ETA: 3:57 - loss: 0.6968 - acc: 0.5117
 800/1726 [============>.................] - ETA: 3:14 - loss: 0.6972 - acc: 0.5075
1000/1726 [================>.............] - ETA: 2:32 - loss: 0.6991 - acc: 0.4990
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6981 - acc: 0.5008
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6977 - acc: 0.5071
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6953 - acc: 0.5169 
1726/1726 [==============================] - 416s 241ms/step - loss: 0.6949 - acc: 0.5168 - val_loss: 0.6879 - val_acc: 0.5520
Epoch 2/50

 200/1726 [==>...........................] - ETA: 5:20 - loss: 0.6861 - acc: 0.5450
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6875 - acc: 0.5450
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6871 - acc: 0.5283
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6860 - acc: 0.5375
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6857 - acc: 0.5460
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6860 - acc: 0.5475
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6855 - acc: 0.5500
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6843 - acc: 0.5538 
1726/1726 [==============================] - 415s 241ms/step - loss: 0.6837 - acc: 0.5545 - val_loss: 0.6836 - val_acc: 0.5749
Epoch 3/50

 200/1726 [==>...........................] - ETA: 5:18 - loss: 0.6902 - acc: 0.5300
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6864 - acc: 0.5500
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6796 - acc: 0.5700
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6784 - acc: 0.5763
1000/1726 [================>.............] - ETA: 2:32 - loss: 0.6767 - acc: 0.5760
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6760 - acc: 0.5825
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6775 - acc: 0.5807
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6770 - acc: 0.5819 
1726/1726 [==============================] - 415s 241ms/step - loss: 0.6772 - acc: 0.5794 - val_loss: 0.6790 - val_acc: 0.5722
Epoch 4/50

 200/1726 [==>...........................] - ETA: 5:20 - loss: 0.6761 - acc: 0.6050
 400/1726 [=====>........................] - ETA: 4:38 - loss: 0.6739 - acc: 0.6075
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6742 - acc: 0.5967
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6738 - acc: 0.5950
1000/1726 [================>.............] - ETA: 2:32 - loss: 0.6702 - acc: 0.6010
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6730 - acc: 0.5925
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6737 - acc: 0.5864
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6734 - acc: 0.5875 
1726/1726 [==============================] - 414s 240ms/step - loss: 0.6733 - acc: 0.5875 - val_loss: 0.6784 - val_acc: 0.5709
Epoch 5/50

 200/1726 [==>...........................] - ETA: 5:18 - loss: 0.6778 - acc: 0.5500
 400/1726 [=====>........................] - ETA: 4:36 - loss: 0.6680 - acc: 0.6050
 600/1726 [=========>....................] - ETA: 3:54 - loss: 0.6735 - acc: 0.5850
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6727 - acc: 0.5850
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6735 - acc: 0.5810
1200/1726 [===================>..........] - ETA: 1:49 - loss: 0.6724 - acc: 0.5892
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6683 - acc: 0.5993
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6695 - acc: 0.5975 
1726/1726 [==============================] - 414s 240ms/step - loss: 0.6694 - acc: 0.5997 - val_loss: 0.6769 - val_acc: 0.5735
Epoch 6/50

 200/1726 [==>...........................] - ETA: 5:19 - loss: 0.6362 - acc: 0.6850
 400/1726 [=====>........................] - ETA: 4:36 - loss: 0.6499 - acc: 0.6600
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6533 - acc: 0.6483
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6576 - acc: 0.6425
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6612 - acc: 0.6320
1200/1726 [===================>..........] - ETA: 1:49 - loss: 0.6636 - acc: 0.6233
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6651 - acc: 0.6186
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6663 - acc: 0.6087 
1726/1726 [==============================] - 414s 240ms/step - loss: 0.6669 - acc: 0.6101 - val_loss: 0.6761 - val_acc: 0.5843
Epoch 7/50

 200/1726 [==>...........................] - ETA: 5:18 - loss: 0.6687 - acc: 0.6250
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6690 - acc: 0.6100
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6632 - acc: 0.6233
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6681 - acc: 0.6088
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6688 - acc: 0.5990
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6685 - acc: 0.5975
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6644 - acc: 0.6036
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6660 - acc: 0.5981 
1726/1726 [==============================] - 415s 240ms/step - loss: 0.6634 - acc: 0.6043 - val_loss: 0.6748 - val_acc: 0.5762
Epoch 8/50

 200/1726 [==>...........................] - ETA: 5:18 - loss: 0.6690 - acc: 0.5950
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6689 - acc: 0.5950
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6653 - acc: 0.6083
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6635 - acc: 0.6100
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6610 - acc: 0.6190
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6653 - acc: 0.6125
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6606 - acc: 0.6250
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6621 - acc: 0.6156 
1726/1726 [==============================] - 415s 240ms/step - loss: 0.6610 - acc: 0.6194 - val_loss: 0.6746 - val_acc: 0.5816
Epoch 9/50

 200/1726 [==>...........................] - ETA: 5:17 - loss: 0.6733 - acc: 0.6000
 400/1726 [=====>........................] - ETA: 4:36 - loss: 0.6830 - acc: 0.5750
 600/1726 [=========>....................] - ETA: 3:54 - loss: 0.6735 - acc: 0.5967
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6680 - acc: 0.6063
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6686 - acc: 0.5940
1200/1726 [===================>..........] - ETA: 1:49 - loss: 0.6650 - acc: 0.5975
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6632 - acc: 0.6029
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6615 - acc: 0.6125 
1726/1726 [==============================] - 414s 240ms/step - loss: 0.6599 - acc: 0.6130 - val_loss: 0.6774 - val_acc: 0.5938
Epoch 10/50

 200/1726 [==>...........................] - ETA: 5:19 - loss: 0.6336 - acc: 0.7000
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6389 - acc: 0.6775
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6497 - acc: 0.6483
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6461 - acc: 0.6500
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6548 - acc: 0.6350
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6611 - acc: 0.6225
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6602 - acc: 0.6221
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6592 - acc: 0.6262 
1726/1726 [==============================] - 415s 240ms/step - loss: 0.6581 - acc: 0.6257 - val_loss: 0.6714 - val_acc: 0.5938
Epoch 11/50

 200/1726 [==>...........................] - ETA: 5:18 - loss: 0.6517 - acc: 0.6200
 400/1726 [=====>........................] - ETA: 4:36 - loss: 0.6550 - acc: 0.6275
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6460 - acc: 0.6483
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6494 - acc: 0.6375
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6531 - acc: 0.6240
1200/1726 [===================>..........] - ETA: 1:49 - loss: 0.6513 - acc: 0.6258
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6549 - acc: 0.6179
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6569 - acc: 0.6125 
1726/1726 [==============================] - 415s 240ms/step - loss: 0.6568 - acc: 0.6107 - val_loss: 0.6712 - val_acc: 0.5965
Epoch 12/50

 200/1726 [==>...........................] - ETA: 5:19 - loss: 0.6520 - acc: 0.6300
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6606 - acc: 0.6275
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6606 - acc: 0.6183
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6558 - acc: 0.6238
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6531 - acc: 0.6320
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6547 - acc: 0.6267
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6534 - acc: 0.6257
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6547 - acc: 0.6231 
1726/1726 [==============================] - 415s 240ms/step - loss: 0.6550 - acc: 0.6228 - val_loss: 0.6721 - val_acc: 0.5965
Epoch 13/50

 200/1726 [==>...........................] - ETA: 5:19 - loss: 0.6562 - acc: 0.6300
 400/1726 [=====>........................] - ETA: 4:37 - loss: 0.6634 - acc: 0.6225
 600/1726 [=========>....................] - ETA: 3:55 - loss: 0.6618 - acc: 0.6217
 800/1726 [============>.................] - ETA: 3:13 - loss: 0.6651 - acc: 0.6088
1000/1726 [================>.............] - ETA: 2:31 - loss: 0.6563 - acc: 0.6250
1200/1726 [===================>..........] - ETA: 1:50 - loss: 0.6506 - acc: 0.6342
1400/1726 [=======================>......] - ETA: 1:08 - loss: 0.6487 - acc: 0.6329
1600/1726 [==========================>...] - ETA: 26s - loss: 0.6513 - acc: 0.6300 
1726/1726 [==============================] - 415s 240ms/step - loss: 0.6528 - acc: 0.6251 - val_loss: 0.6739 - val_acc: 0.5938
personality_NEU.py:283: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.
  merged = Merge([modelleft,modelright], mode='concat',name='Merge')
